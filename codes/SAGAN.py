import os
import time
import torch
from torch.utils.data import DataLoader
import torch.nn as nn
from SN import SpectralNorm
from SelfAttn import SelfAttn
from torchvision import transforms
from torchvision.datasets import MNIST
from torchvision.utils import save_image

def cuda(data):
  if torch.cuda.is_available():
    return data.cuda()
  else:
    return data

def denorm(x):
  out = (x+1)/2
  return out.clamp_(0,1)

fixed_z = cuda(torch.randn(64, 100))
batch_size = 64

# Define data transformer
img_transform = transforms.Compose([
    transforms.Resize(28),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))])

# Read data and transform
dataset = MNIST(root='./data', download=True, train=True, transform=img_transform)
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

class Generator(nn.Module):
    """
    Generator
    input: 
        z: latent matrix with shape of (batch_size, 100)
    output: 
        out: generated image with shape (batch_size, 1, 28, 28)
        p1: attention matrix generated by attn layer
    """
    def __init__(self, attn=True, batch_size=64, image_size=28, z_dim=100, conv_dim=64):
        super(Generator, self).__init__()

        layer1 = []
        layer1.append(SpectralNorm(nn.ConvTranspose2d(in_channels=z_dim, out_channels=conv_dim*8, kernel_size=3, padding=0, stride=1)))
        layer1.append(nn.BatchNorm2d(conv_dim*8))
        layer1.append(nn.ReLU())
        self.l1 = nn.Sequential(*layer1)

        layer2 = []
        layer2.append(SpectralNorm(nn.ConvTranspose2d(in_channels=conv_dim*8, out_channels=conv_dim*4, kernel_size=3, padding=0, stride=2)))
        layer2.append(nn.BatchNorm2d(conv_dim*4))
        layer2.append(nn.ReLU())
        self.l2 = nn.Sequential(*layer2)

        layer3 = []
        layer3.append(SpectralNorm(nn.ConvTranspose2d(in_channels=conv_dim*4, out_channels=conv_dim*2, kernel_size=4, padding=1, stride=2)))
        layer3.append(nn.BatchNorm2d(conv_dim*2))
        layer3.append(nn.ReLU())
        self.l3 = nn.Sequential(*layer3)

        layer4 = []
        layer4.append(SpectralNorm(nn.ConvTranspose2d(in_channels=conv_dim*2, out_channels=1, kernel_size=4, padding=1, stride=2)))
        layer4.append(nn.Tanh())
        self.l4 = nn.Sequential(*layer4)

        self.attn = attn
        self.attn = SelfAttn(in_dim=conv_dim*2)


    def forward(self, z):
        z = z.view(z.size(0), z.size(1), 1, 1)
        out = self.l1(z)
        out = self.l2(out)
        out = self.l3(out)
        if self.attn:
            out = self.attn(out)
        out = self.l4(out)
        return out



class Discriminator(nn.Module):
    def __init__(self, attn=True, batch_size=64, image_size=28, conv_dim=64):
        super(Discriminator, self).__init__()
        layer1 = []
        layer1.append(SpectralNorm(nn.Conv2d(in_channels=1, out_channels=conv_dim, kernel_size=4, stride=2, padding=1)))
        layer1.append(nn.LeakyReLU(0.1))
        self.l1 = nn.Sequential(*layer1)

        layer2 = []
        layer2.append(SpectralNorm(nn.Conv2d(in_channels=conv_dim, out_channels=conv_dim*2, kernel_size=4, stride=2, padding=1)))
        layer2.append(nn.LeakyReLU(0.1))
        self.l2 = nn.Sequential(*layer2)

        layer3 = []
        layer3.append(SpectralNorm(nn.Conv2d(in_channels=conv_dim*2, out_channels=conv_dim*4, kernel_size=4, stride=2, padding=1)))
        layer3.append(nn.LeakyReLU(0.1))
        self.l3 = nn.Sequential(*layer3)

        layer4 = []
        layer4.append(SpectralNorm(nn.Conv2d(in_channels=conv_dim*4, out_channels=1, kernel_size=4, stride=2, padding=1)))
        self.l4 = nn.Sequential(*layer4)
        self.attn = attn
        self.attn = SelfAttn(in_dim=conv_dim*2)

    def forward(self, x):
        out = self.l1(x)
        out = self.l2(out)
        out = self.l3(out)
        if self.attn:
            out = self.attn(out)
        out = self.l4(out)
        return out      



         

def train(steps=100000, batch_size=64, z_dim=100, attn=True):
    G = Generator()
    D = Discriminator()

    cwd = os.getcwd()
    post='_attn' if attn else ''
    if not os.path.exists(cwd+'/samples_mnist'+post):
        os.makedirs(cwd+'/samples_mnist'+post)

    g_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, G.parameters()), 0.0001, [0.0,0.9])
    d_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, D.parameters()), 0.0004, [0.0,0.9])
    Iter = iter(dataloader)

    start_time = time.time()
    fixed_z = cuda(torch.randn(1, z_dim))
    for step in range(steps):
        try:
            real_images, _ = next(Iter)
        except:
            Iter = iter(dataloader)
            real_images, _ = next(Iter)

        #train Discriminator
        for i in range(3):
            z = cuda(torch.randn(batch_size, z_dim))
            loss = (torch.log(D(cuda(real_images))) + torch.log(1-D(G(z)))).mean()
            loss.backward()
            d_optimizer.zero_grad()
            g_optimizer.zero_grad()
            d_optimizer.step()
        z = cuda(torch.randn(batch_size, z_dim))
        loss = -torch.log(D(G(z))).mean()
        loss.backward()
        d_optimizer.zero_grad()
        g_optimizer.zero_grad()
        g_optimizer.step()

        if (step+1) % 10 == 0:
            elapsed = time.time()-start_time
        
        if (step+1) % 100 == 0:
            image = G(z)
            save_image(denorm(image), cwd+'/samples_mnist'+post+'/epoch'+str(step))

        





            

